/* DO NOT EDIT THIS FILE - it is machine generated */

#define END_PROF(X)
#define START_PROF(X)
#define SCOPE_PROF(X)

#include <ctime>

#include <jni.h>
#include <ctime>
#include <vector>
#include <cstring>
#include <android/log.h>
#include <cuimg/gl.h>
#include <cuimg/draw.h>
#include <cuimg/neighb2d_data.h>
#include <cuimg/cpu/host_image2d.h>
#include <cuimg/cpu/convolve.h>
#include <cuimg/tracking2/tracker.h>
#include <cuimg/cpu/gaussian_blur.h>


#include "spy_demo_CameraStream.h"
#include "common.hh"

using namespace cuimg;

class camera_motion_estimator
{
public:
  camera_motion_estimator(const obox2d& _domain, int _n_frames)
    : H(_domain),
      H_blur(H.domain()),
      H_tmp(H.domain()),
      display(H.domain()),
      n_frames(_n_frames),
      domain(_domain)
  {
  }

  i_int2 estimate_camera_motion(std::vector<trajectory>& v, int scale)
  {
    memset(H, 0);
    for (auto& t : v)
    {
      if (t.age() > n_frames)
      {
	i_int2 bin(t.disp(n_frames) + i_int2(H.nrows()/2, H.ncols()/2));
	if ((H.domain() - border(3)).has(bin))	H(bin)++;
      }
    }

    fill(H_blur, 0);
    fill(H_tmp, 0);

    gaussian_blur_sigma1(H, H_blur, H_tmp);
    gaussian_blur_sigma1(H_blur, H, H_tmp);
    gaussian_blur_sigma1(H, H_blur, H_tmp);

    [&] (i_int2 p) { display(p) = i_float4(H(p) / 10.f, H(p) / 10.f, H(p) / 10.f, 1.f); } >> iterate(display.domain());

    i_int2 max_bin;
    int max_v = 0;
    [&] (i_int2 p) { if (H_blur(p) > max_v) { max_bin = p; max_v = H_blur(p);}  } >> iterate(display.domain());

    draw_c8(display, max_bin, i_float4(1.f, 0,0, 1.f));
    if (max_v)
      return (max_bin - i_int2(H.nrows()/2, H.ncols()/2));
    else return zero();
  }

  void is_background(i_int2 p)
  {
  }

  host_image2d<int> H;
  host_image2d<int> H_blur;
  host_image2d<int> H_tmp;
  host_image2d<i_float4> display;
  int n_frames;
  obox2d domain;
};


template <typename A, typename B>
float max_traj_dist(const A& a, const B& b)
{
  int a_age = a.age();
  int b_age = b.age();

  int m = std::min(a_age, b_age);

  if (m <= 2)
    return 0.f;

  int delta = m > 20 ? 20 : m;
  float max = 0;
  for (unsigned i = 0; i < delta; i++)
  {
    float x = norml2((a.history[a_age-1] - a.history[a_age-i-1]) -
		     (b.history[b_age-1] - b.history[b_age-i-1]));
    max = std::max(x, max);
  }

  return max;
}


struct bg_sub_environment
{
public:
  typedef tracker<tracking_strategies::bc2s_miel3_gradient_cpu> T;
  bg_sub_environment() { fps = 0; tr = 0; tracking_time = 0.f; }

  void update(obox2d domain, const unsigned char* yuv, unsigned char* out_rgba)
  {
    const int disp_size = 1;
    if (not (gl_frame.domain() == domain))
    {
      if (tr) 
      {
	delete tr;
	delete cme;
      }

      tr = new T(domain, 2);
      tr->scale(0).strategy().detector().set_contrast_threshold(10);
      tr->scale(1).strategy().detector().set_contrast_threshold(10);
      tr->scale(2).strategy().detector().set_contrast_threshold(10);
      tr->strategy().set_detector_frequency(5).set_filtering_frequency(5);

      cme = new camera_motion_estimator(domain, disp_size);
      bg_traj.history.clear();
      bg_traj.history.push_back(i_int2(0,0));

      gl_frame = host_image2d<gl8u>(domain);
      gl_blur = host_image2d<gl8u>(domain);
      __android_log_print(ANDROID_LOG_ERROR, "tag", "Input size is %i x %i", gl_frame.ncols(), gl_frame.nrows());
    }

    nv21_to_gl(domain.ncols(), domain.nrows(), yuv, (unsigned char*) gl_frame.data());

    double t = get_time();
    tr->run(gl_frame);

    tr->scale(0).pset().sync_attributes(trajectories, trajectory());
    update_trajectories(trajectories, tr->scale(0).pset());

    i_int2 cm = cme->estimate_camera_motion(trajectories, 1);

    if (bg_traj.age() > disp_size)
      bg_traj.history.push_back(bg_traj.history[bg_traj.age() - disp_size] + cm);
    else
      bg_traj.history.push_back(zero());
    if (bg_traj.history.size() > 20) bg_traj.history.pop_front();


    host_image2d<i_uchar4> out((i_uchar4*) out_rgba, domain.nrows(), domain.ncols(), 4 * domain.ncols() * sizeof(unsigned char));

    fill(out, i_uchar4(0,0,0,255));
    //gl_to_rgba(domain.ncols(), domain.nrows(), (unsigned char*) gl_frame.data(), out_rgba);
    for (trajectory& t : trajectories)
    {
      if (t.age() > 1)
      {
    	if (max_traj_dist(t, bg_traj) < (gl_frame.ncols() / 20))
    	  draw_c8(out, t.pos(), i_uchar4(255, 0,0, 255));
    	else
    	  draw_c8(out, t.pos(), i_uchar4(0, 0,255, 255));
      }
    }

    if ((get_time() - time) > 1. && fps)
    {
      time = get_time();
      __android_log_print(ANDROID_LOG_ERROR, "tag", "Tracking xxx time %f ms/frame", tracking_time*1000.f/fps);
      __android_log_print(ANDROID_LOG_ERROR, "tag", "Fps %i, %i points @ %ix%i", fps, tr->pset().size(), domain.ncols(), domain.nrows());
      fps = 0;
      tracking_time = 0.;
    }

    fps++;
  }
private:

  T* tr;
  camera_motion_estimator* cme;
  trajectory bg_traj;
  host_image2d<gl8u> gl_frame;
  host_image2d<i_uchar1> gl_blur;
  double time;
  unsigned fps;
  double tracking_time;

  std::vector<trajectory> trajectories;

};

static bg_sub_environment cppenv;

void Java_spy_demo_CameraStream_backgroundsubstraction(JNIEnv* env, jobject thiz, jint width,
							jint height, jbyteArray yuv, jintArray bgra)
{
  jbyte* _yuv  = env->GetByteArrayElements(yuv, 0);
  jint*  _bgra = env->GetIntArrayElements(bgra, 0);

  unsigned char* in = (unsigned char *)_yuv;
  unsigned char* buf = (unsigned char *)_bgra;

  cppenv.update(obox2d(height, width), in, buf);

  env->ReleaseIntArrayElements(bgra, _bgra, 0);
  env->ReleaseByteArrayElements(yuv, _yuv, 0);
}
